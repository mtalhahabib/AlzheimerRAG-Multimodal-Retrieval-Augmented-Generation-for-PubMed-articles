# ğŸ§  Intelligent Virtual Assistant for Alzheimer's Disease (RAG-based)

An AI-powered virtual assistant designed to provide medical insights for Alzheimer's Disease using **Retrieval-Augmented Generation (RAG)**. This system fetches medical articles from **PubMed**, stores them in a vector database, and generates responses using a powerful LLM â€” **LLaMA 8B (via Hugging Face)**.

---

## ğŸš€ Features

- ğŸ” **Dynamic Article Retrieval** from [PubMed](https://pubmed.ncbi.nlm.nih.gov/)
- ğŸ§  **RAG Architecture**: combines retrieval + generation for contextual responses
- ğŸ§¬ Uses **Chroma DB** as the vector store
- ğŸ¤– Integrated with **LLaMA 8B** model (Hugging Face) for advanced natural language responses
- ğŸ©º Tailored to Alzheimerâ€™s-related research and user queries
- âš™ï¸ CLI or API-based interaction with the assistant

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| Language Model | [`LLaMA 8B`](https://huggingface.co/) (Hugging Face) |
| Vector DB | [`Chroma`](https://www.trychroma.com/) |
| Retrieval | Custom PubMed scraper & parser |
| Architecture | Retrieval-Augmented Generation (RAG) |
| Backend | Python, LangChain (if applicable) |

---

## âš ï¸ Current Limitations

1. **Contextual Learning Issues**  
   â†’ The system struggles to maintain deep context across multiple queries, especially in multi-turn interactions.

2. **Performance Trade-Off**  
   - Increasing the number of PubMed articles improves context, but **drastically slows down** the system.  
   - Reducing articles improves performance but **weakens answer quality**.

3. **Memory & Latency**  
   - Loading large datasets into memory for LLaMA 8B and embeddings can significantly increase latency.

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ pubmed_scraper/
â”‚   â””â”€â”€ fetch_articles.py       # Fetches and parses articles from PubMed
â”œâ”€â”€ embedding/
â”‚   â””â”€â”€ vector_store.py         # Chroma DB setup and ingestion
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ llama_interface.py      # Hugging Face integration with LLaMA 8B
â”œâ”€â”€ app.py                      # Main app logic for query processing
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
